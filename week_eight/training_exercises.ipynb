{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Training Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Exercise M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Given the model and values, calculate the values of the vector $e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1:  [-0.61 -4.06 -9.12 -1.19 -0.13]\n",
      "e2:  [ 6.81  7.29 -0.61 -0.08  2.4 ]\n"
     ]
    }
   ],
   "source": [
    "# Create the data for the model y = Xb + e\n",
    "\n",
    "y = np.array([15.1, 7.9, 4.5, 12.8, 10.5])\n",
    "\n",
    "X = np.array(\n",
    "    [[1,25.5,1.23]\n",
    "     ,[1,40.8,1.89]\n",
    "     ,[1,30.2,1.55]\n",
    "     ,[1,4.3,1.18]\n",
    "     ,[1,10.7,1.68]]\n",
    ")\n",
    "\n",
    "b_1 = np.array([23, 0.1, -8])\n",
    "b_2 = np.array([22, -0.2, -7])\n",
    "\n",
    "# Calculate e\n",
    "e_1 = y - np.matmul(X, b_1)\n",
    "e_2 = y - np.matmul(X, b_2)\n",
    "\n",
    "# Print results\n",
    "print(\"e1: \", e_1)\n",
    "print(\"e2: \", e_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Which $b$ gives the smallest $e$ by both absolute value and by squaring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't observe a strict order on the resultant $e$ vectors, since the calculations are done component-wise. However, if we aggregate the resultant $e$ vectors by summing them component-wise, then with respect to both measures, $b_1$ appears to produce the smallest $e$.\n",
    "\n",
    "Detailed calculations are included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Absolute --------\n",
      "e1\n",
      "\tabs: [0.61 4.06 9.12 1.19 0.13]\n",
      "\tsum: 15.11\n",
      "e2\n",
      "\tabs: [6.81 7.29 0.61 0.08 2.4 ]\n",
      "\tsum: 17.19\n",
      "-------- Squared --------\n",
      "e1\n",
      "\tabs: [3.72100e-01 1.64836e+01 8.31744e+01 1.41610e+00 1.69000e-02]\n",
      "\tsum: 101.46309999999998\n",
      "e2\n",
      "\tabs: [4.63761e+01 5.31441e+01 3.72100e-01 6.40000e-03 5.76000e+00]\n",
      "\tsum: 105.65870000000002\n"
     ]
    }
   ],
   "source": [
    "# Calculate e sizes\n",
    "e_1_abs = np.abs(e_1)\n",
    "e_2_abs = np.abs(e_2)\n",
    "\n",
    "e_1_sq = np.square(e_1)\n",
    "e_2_sq = np.square(e_2)\n",
    "\n",
    "# Print results\n",
    "print(\"-------- \"+\"Absolute\"+\" --------\")\n",
    "print(\"e1\")\n",
    "print(\"\\tabs:\", e_1_abs)\n",
    "print(\"\\tsum:\", np.sum(e_1_abs))\n",
    "print(\"e2\")\n",
    "print(\"\\tabs:\", e_2_abs)\n",
    "print(\"\\tsum:\", np.sum(e_2_abs))\n",
    "\n",
    "print(\"-------- \"+\"Squared\"+\" --------\")\n",
    "print(\"e1\")\n",
    "print(\"\\tabs:\", e_1_sq)\n",
    "print(\"\\tsum:\", np.sum(e_1_sq))\n",
    "print(\"e2\")\n",
    "print(\"\\tabs:\", e_2_sq)\n",
    "print(\"\\tsum:\", np.sum(e_2_sq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Find the dimension of d and write it in sigma notation $\\left(\\Sigma\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since\n",
    "\n",
    "$$ d = u_{1 \\times p} \\cdot A_{p \\times q} \\cdot v_{q \\times 1} $$\n",
    "\n",
    "it follows $d$ is $(1 \\times 1)$ (a scalar). We can compute $d$ by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    d &= \\sum_{r=1}^p u_{ir} \\left[ Av \\right]_{r1} \\\\\n",
    "    &= \\sum_{r=1}^{p} u_{ir} \\left( \\Sigma_{s=1}^q a_{rs} v_{s1} \\right) \\\\\n",
    "    &= \\sum_{r=1}^{p} \\sum_{s=1}^{q} u_{ir} a_{rs} v_{s1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Simplify $\\left( A + I \\right)^2$ with $A$ $(p \\times p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "$$\n",
    "    (A + I)^2 = A^2 + 2A + I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Exercise M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Find $(a+b)^T (a+b)$ for $a,b$ $(p \\times 1)$ vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    (a+b)^T (a+b) &= (b^T + a^T) (a+b) \\\\\n",
    "    &= b^Ta + b^Tb + a^Ta + a^Tb \\\\\n",
    "    &= a^Ta + 2a^Tb + b^Tb\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Let $a$ be $(p \\times 1)$. Show $\\text{tr}(a^Ta) = \\text{tr}(aa^T)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Observe that\n",
    "\n",
    "$$ \\left[ a a^T \\right]_{ii} = a_{i1} [a^T]_{1i} = a_{i}^2 $$\n",
    "\n",
    "which immediately implies the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Let $A$ be square $(p \\times p)$ and $c$ a scalar. Show $\\text{tr}(cA) = c \\text{tr}(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{tr}(cA) &= \\sum_{i=1}^p c a_{ii} \\\\\n",
    "    &= c \\sum_{i=1}^p a_{ii} \\\\\n",
    "    &= c \\text{tr}(A)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Let $A$ be square $(p \\times p)$ and invertible and $c \\neq 0$ a scalar.Find $(cA)^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Observe\n",
    "\n",
    "$$ \\frac{1}{c}A^{-1} cA = \\frac{1}{c} c A^{-1}A = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Find the value of $f$ that makes $B$ the inverse of $A$ and state the condition the elements of $A$ must satisfy so that the inverse exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** If $f = ad - bc \\neq 0 $ then one can verify that $ AB = BA = I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Simplify $\\iota^T \\iota$ and $(\\iota \\iota^T)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Observe that\n",
    "\n",
    "$$ \\iota^T \\iota = \\sum_{i=1}^p (1 \\cdot 1) = p $$\n",
    "\n",
    "and that\n",
    "\n",
    "$$ (\\iota \\iota^T) = \\begin{bmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\begin{bmatrix} 1 &\\ldots & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & \\ldots & 1 \\\\ \\vdots & \\ddots & \\vdots \\\\ 1 &\\ldots & 1 \\end{bmatrix} $$\n",
    "\n",
    "so that\n",
    "\n",
    "$$ \\left[ (\\iota \\iota^T)^2 \\right]_{ij} = \\sum_{r=1}^p (\\iota \\iota^T)_{pr} (\\iota \\iota^T)_{rp} = \\sum_{r=1}^p 1 \\cdot 1 = p $$\n",
    "\n",
    "and therefore\n",
    "\n",
    "$$ (\\iota \\iota^T)^2 = \\begin{bmatrix} p & \\ldots & p \\\\ \\vdots & \\ddots & \\vdots \\\\ p & \\ldots & p \\end{bmatrix} = p \\iota \\iota^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Exercise M3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Find the gradient and Hessian of $f(b) = b^T b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** We have that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial f}{\\partial b_i} (b) &= \\frac{\\partial}{\\partial b_i} \\left( \\sum_{r=1}^p b_r^2 \\right) \\\\\n",
    "    &= \\sum_{r=1}^p \\frac{\\partial}{\\partial b_i} b_r^2 \\\\\n",
    "    &= 2b_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial b} (b) = 2b $$\n",
    "\n",
    "For the Hessian, we have that\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial b_i \\partial b_j} (b) = \\frac{\\partial}{\\partial b_i} \\left( 2b_j \\right) $$\n",
    "\n",
    "so that\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial f}{\\partial b \\partial b^T} (b) = \\begin{cases} 2 & ,i=j \\\\ 0 & ,\\text{otherwise} \\end{cases} = 2I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Prove a diagonal matrix is positive definite if all diagonal elements are positive, and negative definite if all diagonal elements are negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof:** Let $D$ be a $(p \\times p)$ diagonal matrix and let $x \\neq 0$ be a $(p \\times 1)$ vector. Then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    x^T D x &= \\sum_{r=1}^p [x^T]_{1r} \\left[ Dx \\right]_{r1} \\\\\n",
    "    &= \\sum_{r=1}^p x_r d_{rr} x_r \\\\\n",
    "    &= \\sum_{r=1}^p d_{rr} x_r^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "so that, since $x \\neq 0$, $x^T D x$ is positive definite when $d_{rr} > 0$ for all $1 \\leq r \\leq p$ and is negative definite when $d_{rr} < 0$ for all $1 \\leq r \\leq p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Given $y = Xb + e$ with the stated assumptions, find the vector $b^*$ that minimizes $f(b) = e^T e$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Since $e = e(b) = y - Xb$ it follows that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    f(b) &= \\left( y - Xb \\right)^T \\left( y - Xb \\right) \\\\\n",
    "    &= y^Ty - 2y^TXb + b^TX^TXb\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now, since $\\frac{\\partial x^TAx}{\\partial x} (x) = \\left( A + A^T \\right) x$ it follows that\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial f}{\\partial b} (b)  = -2X^Ty + 2X^TXb\n",
    "$$\n",
    "\n",
    "so that, by invertibility of $X^TX$ which follows from $X$ having full column-rank, solving $\\frac{\\partial f}{\\partial b} (b^*) = 0$ yields\n",
    "\n",
    "$$ b^* =  \\left( X^TX \\right)^{-1} y^TX $$\n",
    "\n",
    "so that\n",
    "\n",
    "$$ H(b^*) = 2X^TX $$\n",
    "\n",
    "and since $X$ has full column-rank, $Xv = 0$ if and only if $v = 0$. Thus\n",
    "\n",
    "$$ v^T X^TX v = (Xv)^T (Xv) > 0 $$\n",
    "\n",
    "since $v \\neq 0$ implies $Xv \\neq 0$. Thus $b^*$ minimizes $f$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8fa3177836abb39d5e3b555ef652ac0e569b7e89a422512b518d324b09235a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
